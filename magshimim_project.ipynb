{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28370daf",
   "metadata": {},
   "source": [
    "# Magshimim Project\n",
    "\n",
    "## Practical NLP with Classical ML + Pretrained Transformers\n",
    "\n",
    "This notebook is a **portfolio-style NLP project** that demonstrates a complete workflow:\n",
    "\n",
    "- Build a strong **baseline** sentiment classifier (TF‑IDF + Logistic Regression)\n",
    "- Compare it with a **pretrained Transformer** sentiment model\n",
    "- Use pretrained models for **translation** and **summarization**\n",
    "- Combine multiple pretrained models into a small **customer-support assistant** (language detection + summarization + QA)\n",
    "\n",
    "Everything is written to be **readable, reproducible, and GitHub-friendly** (clear structure, comments, and minimal noise)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b9e82c",
   "metadata": {},
   "source": [
    "## 0. Setup\n",
    "\n",
    "Run the next cell once (Colab-friendly). If you're not on Colab and already have the packages installed, you can skip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c5be99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional installs (recommended for Google Colab)\n",
    "# If you're running locally and already have these packages, you can comment this out.\n",
    "\n",
    "!pip -q install -U transformers evaluate scikit-learn nltk datasets\n",
    "\n",
    "import nltk\n",
    "nltk.download('movie_reviews')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd9c6f1",
   "metadata": {},
   "source": [
    "## 1. Imports & Utilities\n",
    "\n",
    "Small helper functions used throughout the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2720ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import re\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import movie_reviews, stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b0fa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing\n",
    "STOP_WORDS = set(stopwords.words(\"english\"))\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"Lightweight text cleaning suitable for TF‑IDF baselines.\n",
    "\n",
    "    Notes:\n",
    "      - For Transformer pipelines we typically do *less* manual cleaning,\n",
    "        because the tokenizer expects natural text.\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z\\s]\", \" \", text)     # keep letters/spaces only\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # normalize whitespace\n",
    "    return text\n",
    "\n",
    "def tokenize_and_filter(text: str) -> List[str]:\n",
    "    \"\"\"Tokenize and remove stop-words. Used as TF‑IDF tokenizer.\"\"\"\n",
    "    tokens = word_tokenize(text)\n",
    "    return [t for t in tokens if t not in STOP_WORDS and len(t) > 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3433da0e",
   "metadata": {},
   "source": [
    "## 2. Dataset: NLTK Movie Reviews\n",
    "\n",
    "We use the classic **movie_reviews** dataset (binary sentiment: positive/negative). It's small, but great for demonstrating end-to-end modeling and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59df6211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_movie_reviews() -> pd.DataFrame:\n",
    "    \"\"\"Load NLTK movie_reviews into a DataFrame with columns: text, label.\"\"\"\n",
    "    rows = []\n",
    "    for file_id in movie_reviews.fileids():\n",
    "        label = movie_reviews.categories(file_id)[0]  # 'pos' or 'neg'\n",
    "        words = movie_reviews.words(file_id)\n",
    "        text = \" \".join(words)\n",
    "        rows.append((text, label))\n",
    "    return pd.DataFrame(rows, columns=[\"text\", \"label\"])\n",
    "\n",
    "df = load_movie_reviews()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b0681a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick sanity checks\n",
    "print(\"Rows:\", len(df))\n",
    "print(df[\"label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1320c825",
   "metadata": {},
   "source": [
    "## 3. Baseline Model: TF‑IDF + Logistic Regression\n",
    "\n",
    "This is a strong and interpretable baseline for text classification.\n",
    "\n",
    "Why this baseline?\n",
    "- TF‑IDF works well on small/medium datasets\n",
    "- Logistic Regression is fast, stable, and provides a solid reference point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae15395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split (stratified to preserve class balance)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"text\"], df[\"label\"], test_size=0.2, random_state=42, stratify=df[\"label\"]\n",
    ")\n",
    "\n",
    "baseline_clf: Pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(\n",
    "        preprocessor=clean_text,\n",
    "        tokenizer=tokenize_and_filter,\n",
    "        ngram_range=(1, 2),         # unigrams + bigrams often help sentiment\n",
    "        min_df=2\n",
    "    )),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000))\n",
    "])\n",
    "\n",
    "baseline_clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16e5613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "baseline_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = baseline_clf.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=\"pos\")\n",
    "\n",
    "print(f\"Baseline accuracy: {acc:.3f}\")\n",
    "print(f\"Baseline F1 (pos): {f1:.3f}\")\n",
    "print(\"\\nClassification report:\\n\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8baddf3",
   "metadata": {},
   "source": [
    "## 4. Pretrained Transformer: Sentiment Pipeline\n",
    "\n",
    "Next, we compare the baseline to a pretrained Transformer sentiment model via `transformers.pipeline(\"sentiment-analysis\")`.\n",
    "\n",
    "Notes:\n",
    "- This model is **not trained specifically** on NLTK movie_reviews.\n",
    "- It outputs labels like `POSITIVE/NEGATIVE`, so we map them to `pos/neg`.\n",
    "- In a real project, you'd likely fine-tune a model on your dataset, but here we keep it lightweight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741d60a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "sentiment_pipe = pipeline(\"sentiment-analysis\")  # uses a default checkpoint\n",
    "\n",
    "def map_hf_sentiment_label(label: str) -> str:\n",
    "    \"\"\"Map HF pipeline labels to the dataset labels.\"\"\"\n",
    "    label = label.upper()\n",
    "    if \"POS\" in label:\n",
    "        return \"pos\"\n",
    "    return \"neg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8420e9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on a subset to keep runtime reasonable.\n",
    "# You can increase 'max_samples' if you want a more complete comparison.\n",
    "max_samples = 200\n",
    "\n",
    "X_small = list(X_test[:max_samples])\n",
    "y_small = list(y_test[:max_samples])\n",
    "\n",
    "hf_outputs = sentiment_pipe(X_small, truncation=True)\n",
    "hf_pred = [map_hf_sentiment_label(o[\"label\"]) for o in hf_outputs]\n",
    "\n",
    "acc_hf = accuracy_score(y_small, hf_pred)\n",
    "f1_hf = f1_score(y_small, hf_pred, pos_label=\"pos\")\n",
    "\n",
    "print(f\"Transformer (pipeline) accuracy on {max_samples} samples: {acc_hf:.3f}\")\n",
    "print(f\"Transformer (pipeline) F1 (pos) on {max_samples} samples: {f1_hf:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3910498",
   "metadata": {},
   "source": [
    "## 5. Translation with Pretrained Models\n",
    "\n",
    "Here we demonstrate machine translation using a pretrained model.\n",
    "\n",
    "Tip: translation quality varies a lot by domain; for serious evaluation you would use BLEU / COMET on a labeled dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13e3035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# English → Hebrew translation (commonly used checkpoint)\n",
    "en_he_translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-he\")\n",
    "\n",
    "examples = [\n",
    "    \"What time is it?\",\n",
    "    \"This is a small demo of machine translation using Transformers.\",\n",
    "]\n",
    "\n",
    "for s in examples:\n",
    "    out = en_he_translator(s, max_length=128)[0][\"translation_text\"]\n",
    "    print(\"EN:\", s)\n",
    "    print(\"HE:\", out)\n",
    "    print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7592a0b5",
   "metadata": {},
   "source": [
    "## 6. Summarization with Pretrained Models\n",
    "\n",
    "We use a summarization model to compress long text into a short summary. This is useful as a building block in larger systems (e.g., triaging customer messages)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c0cb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "long_text = (\n",
    "    \"Transformers are a class of deep learning models that have become the standard approach \"\n",
    "    \"for many natural language processing tasks. They rely on attention mechanisms to model \"\n",
    "    \"relationships between tokens in a sequence. This allows them to capture long-range \"\n",
    "    \"dependencies more effectively than earlier architectures, such as RNNs. Today, Transformers \"\n",
    "    \"power applications like translation, summarization, question answering, and conversational assistants.\"\n",
    ")\n",
    "\n",
    "summary = summarizer(long_text, max_length=60, min_length=20, do_sample=False)[0][\"summary_text\"]\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3ffdcf",
   "metadata": {},
   "source": [
    "## 7. Mini Project: Customer-Support Assistant (Multi‑Model Pipeline)\n",
    "\n",
    "This section shows how to combine multiple pretrained models into a small end-to-end feature.\n",
    "\n",
    "Goal:\n",
    "1. Detect language\n",
    "2. (Optional) Summarize long questions\n",
    "3. Answer questions using a QA model given an FAQ context\n",
    "\n",
    "This is intentionally simple, but demonstrates **system design thinking** and model orchestration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01784560",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Language detection\n",
    "lang_detector = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"papluca/xlm-roberta-base-language-detection\"\n",
    ")\n",
    "\n",
    "# Extractive question answering (SQuAD-style)\n",
    "qa_model = pipeline(\n",
    "    \"question-answering\",\n",
    "    model=\"deepset/roberta-base-squad2\"\n",
    ")\n",
    "\n",
    "def detect_language(text: str) -> str:\n",
    "    \"\"\"Return ISO-ish language label from the language detector.\"\"\"\n",
    "    out = lang_detector(text, truncation=True)[0]\n",
    "    return out[\"label\"]\n",
    "\n",
    "def summarize_if_needed(text: str, max_chars: int = 400) -> str:\n",
    "    \"\"\"Summarize long text to keep QA inputs manageable.\"\"\"\n",
    "    if len(text) <= max_chars:\n",
    "        return text\n",
    "    return summarizer(text, max_length=60, min_length=20, do_sample=False)[0][\"summary_text\"]\n",
    "\n",
    "def answer_from_faq(question: str, faq_context: str) -> Dict[str, str]:\n",
    "    \"\"\"Answer a question using extractive QA over the FAQ context.\"\"\"\n",
    "    out = qa_model(question=question, context=faq_context)\n",
    "    return {\"answer\": out.get(\"answer\", \"\"), \"score\": float(out.get(\"score\", 0.0))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304f450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example FAQ data (toy dataset for demo)\n",
    "faq_data = [\n",
    "    {\n",
    "        \"question\": \"Where is my order?\",\n",
    "        \"answer\": \"You can check the status of your order by visiting the 'My Orders' section of your account.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How can I return a product?\",\n",
    "        \"answer\": \"To return a product, please visit our Returns page, generate a return label, and ship the product back within 30 days.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Do you ship internationally?\",\n",
    "        \"answer\": \"Yes, we ship internationally. Shipping fees and delivery times vary by destination.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How do I reset my password?\",\n",
    "        \"answer\": \"Click 'Forgot password' on the login page and follow the instructions sent to your email.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Build a single context string for extractive QA\n",
    "faq_context = \"\\n\".join([f\"Q: {x['question']}\\nA: {x['answer']}\" for x in faq_data])\n",
    "print(faq_context[:400] + \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec7f0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def customer_support_assistant(user_question: str) -> Dict[str, str]:\n",
    "    \"\"\"Simple end-to-end assistant.\n",
    "\n",
    "    Strategy:\n",
    "      - Only answer English questions in this demo (to keep it deterministic).\n",
    "      - Summarize long questions (optional).\n",
    "      - Use extractive QA over an FAQ context.\n",
    "    \"\"\"\n",
    "    lang = detect_language(user_question)\n",
    "\n",
    "    if lang != \"en\":\n",
    "        return {\n",
    "            \"language\": lang,\n",
    "            \"answer\": \"Sorry — this demo currently supports English questions only.\",\n",
    "            \"score\": \"N/A\"\n",
    "        }\n",
    "\n",
    "    q = summarize_if_needed(user_question)\n",
    "    out = answer_from_faq(q, faq_context)\n",
    "\n",
    "    return {\n",
    "        \"language\": lang,\n",
    "        \"answer\": out[\"answer\"],\n",
    "        \"score\": f\"{out['score']:.3f}\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e64199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it\n",
    "tests = [\n",
    "    \"I forgot my password. How do I reset it?\",\n",
    "    \"Do you ship outside the US?\",\n",
    "    \"Where can I track my order?\"\n",
    "]\n",
    "\n",
    "for t in tests:\n",
    "    result = customer_support_assistant(t)\n",
    "    print(\"Q:\", t)\n",
    "    print(\"->\", result)\n",
    "    print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9287e7",
   "metadata": {},
   "source": [
    "## 8. Notes, Limitations, and Next Steps\n",
    "\n",
    "**What this project shows well:**\n",
    "- Clean baseline modeling (TF‑IDF + Logistic Regression)\n",
    "- Practical use of pretrained Transformers (sentiment, translation, summarization, QA)\n",
    "- A small but realistic multi-model pipeline\n",
    "\n",
    "**Limitations (intentional for a lightweight demo):**\n",
    "- No fine-tuning (would improve results on the movie_reviews dataset)\n",
    "- Translation and summarization are not evaluated on a labeled benchmark here\n",
    "\n",
    "**Easy upgrades:**\n",
    "- Fine-tune a Transformer (e.g., DistilBERT) for sentiment on movie_reviews\n",
    "- Add proper evaluation for translation (BLEU/COMET) and summarization (ROUGE)\n",
    "- Support multilingual QA by translating non-English questions into English before QA\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
